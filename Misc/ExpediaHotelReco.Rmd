---
title: "Expedia Hotel Recommendation"
author: "Anandan Balaji"
date: "16 June 2016"
output:
  pdf_document:
    toc: yes
    number_sections: 2
  html_document:
    number_sections: 2
    toc: yes
---

# Introduction

The objective of **Expedia Hotel Recommendation** is to predict the **hotel cluster** for the user. The hotel clusters are numbered based on many parameters like  distance for the city center, amenities like swimming pool, gym etc. They are in the range 1 to 100.


# Deep Dive into Dataset

## Data Files
The following are the data files provided. They can be accessed from the following *kaggle location * (www.kaggle.com/c/expedia-hotel-recommendations/data).

* **train.csv** - the training dataset
* **test.csv** - the test dataset
* **destinations.csv** - hotel search latent attributes
* **sample_submission.csv** - the sample submission file in the correct format

## Important Fields in the dataset

The following are the important fields which are available in the **training** dataset.

* **date_time** - TimeStamp
* `user location info`
     * **posa_continent** - ID of the continent
     * **user_location_contry** - ID of the country where the customer is located
     * **user_location_region** - ID of the region where the customer is located
     * **user_location_city** - ID of the city where the customer is located
* **orig_destination_distance** - Physical distance between the hotel and customer at the time of search
* `stay information`
     * **srch_ci** - Checkin date
     * **srch_co** - Checkout date
     * **srch_adults_cnt** - Number of adults
     * **srch_childrens_cnt** - Number of childrens
     * **srch_rm_cnt** - Number of rooms requested in the search
* `destination hotel info`
     * **srch_destination_id** - ID of the destination hotel
     * **hotel_continent** - Hotel continent
     * **hotel_country**  - Hotel Country
* **is_booking** - 1 if a booking, 0 if a click.
* **cnt** - Number of similar events in the context of same user session.
* **hotel_cluster** - ID of the hotel cluster

Also the **destinations.csv** has the following information.  

* **srch_destination_id** - ID of the destination hotel
* **d1-d149** - latent description of search regions

## Format of Submission File

For every user event, we need to predict a space-delimited list of the hotel clusters they booked. we may submit up to 5 predictions for each user event. The file should contain a header and have the following format:

id,hotel_cluster

0,99 3 1 75 20

1,2 50 30 23 9

etc...

## Limitations of the Dataset
1. The `user location info` ( continent/country/city) and `destination hotel location` (continent/country) are **integer values**. There is no mapping available about the integer values to appripriate cities.
2. The `destination data file` has the information about the hotels in terms of **150 attributes** and they are of **nunerical** value. There is no mapping available for this one as well.


# Exploring the data
## Sampling the training dataset

The **training** dataset has 37M records with 4GB in size. Because of the huge dataset, we can't load the complete training datset in a normal computer. We need to have a machine with atleast **16GB RAM** size.

However, following are some ways to deal with the big data set for exploration and analysis.

  *  **sample the training data** - Use CATools package to create a smaller dataset by sampling as below. Note that the sampling will help in the early explorations. But for **final analysis and prediction, we have to run the complete training and test dataset**. 
  
```{r eval = FALSE}
# for splitting the training data 
library(caTools)

system.time(train_dt <- fread("train.csv", header = TRUE))

#to make it reproducible
set.seed(123)

## specify the column name
split = sample.split(train_dt$hotel_cluster, SplitRatio = 0.75)

new_train_dt = subset(train_dt, split == TRUE)
new_test_dt  = subset(train_dt, split == FALSE)

write.csv(new_train_dt, file = "new_train.csv", row.names = FALSE, quote = FALSE)
write.csv(new_test_dt, file = "new_test.csv", row.names = TRUE, quote = FALSE)
```


  *  **Use fread()** - The fread() from `data.table` package is faster than the read.csv() function.
```{r echo = FALSE, results = FALSE}
library(data.table)
train_dt <- fread("train.25000.csv", header = TRUE)
library(ggplot2)
```
```{r echo = FALSE, message = FALSE}
test_dt <- fread("test.1000.csv")
```

**Note: For this report, will use sampled training dataset, which has 25 thousand observations.**

## Examining the Date info  

Let's take a look at the date info in the **training** dataset.

```{r}
train_dt$year <- as.numeric(format(as.Date(train_dt$date_time, "%Y-%m-%d"), "%Y"))
unique(train_dt$year)
```

Examine the records in the **test** data.


```{r}
test_dt$year <- as.numeric(format(as.Date(test_dt$date_time, "%Y-%m-%d"), "%Y"))
unique(test_dt$year)
```


## User's current location and the destination hotel location

The  posa_continent is user current location at the time of booking and  the hotel_continent is the desitnation location.

 
```{r }
ggplot(train_dt, aes(posa_continent, fill = factor(hotel_continent))) + geom_bar(position = "dodge")
```

## Spread of hotel clusters in different continents.


```{r}
ggplot(train_dt,
       aes(x = hotel_cluster, y = hotel_continent, col = factor(hotel_continent))) +       # to avoid over plotting
  geom_jitter(alpha = 0.7) +
      geom_smooth(method = "lm", se = F)
```

# Approach to solution
## Correlation Info of hotel_cluster with rest of attributes.

```{r}
cor(train_dt$hotel_cluster, train_dt$srch_destination_id)
cor(train_dt$hotel_cluster, train_dt$posa_continent)
cor(train_dt$hotel_cluster, train_dt$user_location_country)

cor(train_dt$hotel_cluster, train_dt$user_location_region)
cor(train_dt$hotel_cluster, train_dt$user_location_city)
cor(train_dt$hotel_cluster, train_dt$orig_destination_distance)

cor(train_dt$hotel_cluster, train_dt$user_id)
cor(train_dt$hotel_cluster, train_dt$is_package)
cor(train_dt$hotel_cluster, train_dt$srch_adults_cnt)

cor(train_dt$hotel_cluster, train_dt$srch_children_cnt)
cor(train_dt$hotel_cluster, train_dt$srch_rm_cnt)
cor(train_dt$hotel_cluster, train_dt$srch_destination_id)

cor(train_dt$hotel_cluster, train_dt$srch_destination_type_id)
cor(train_dt$hotel_cluster, train_dt$is_booking)
cor(train_dt$hotel_cluster, train_dt$cnt)

cor(train_dt$hotel_cluster, train_dt$hotel_continent)
cor(train_dt$hotel_cluster, train_dt$hotel_country)
cor(train_dt$hotel_cluster, train_dt$hotel_market)
```

## Linear Model

```{r}
model = lm(hotel_cluster ~ srch_destination_id + srch_destination_type_id + is_booking + cnt + orig_destination_distance + user_location_country + user_location_region + is_mobile + is_package + hotel_continent + hotel_country + hotel_market, data= train_dt)
summary(model)


#to avoid multi colinearity, try different model
model2 = lm(hotel_cluster ~ srch_destination_id + cnt + orig_destination_distance + user_location_region + hotel_country + hotel_market, data=train_dt)
summary(model2)
```

## Non Linear Model


```{r}
library(rpart)
frmla = hotel_cluster ~ srch_destination_id + user_location_region + orig_destination_distance
ctrl = rpart.control(minSplit=5, minbucket = 50)

expediaTreeModel = rpart(frmla, data = train_dt, method = "class", control=ctrl )

# get the cp - complexity factor
printcp(expediaTreeModel)
```

## Rule based approach

From the linear model results, the R-squared value is negligible. So, the dependent variables are *NOT* correlating well. Using the non linear model - CART (Classification and Regression Tree), which also illustrates that the dependent variables are not correlating well. In this case, these basic Machine Learning algorithms are not much of help for this problem.

Alternatively, we can predict the hotel cluster by formulating a list of rules as below

### Rule 1: Identify the often used hotel cluster for a destination

The idea is to identify the often used hotel cluster for a given destination. In our case, we have to identify the top five hotel cluster.

Also the training dataset has `is_booking` flag, ie., `is_booking` is 1 for the confirmed booking and `is_booking` is 0 for the unconfrimed booking. So, while identifying top five, we can provide more weightage to the confirmed booking.

 
```{r eval = FALSE}

# get the training data
train_dt <- fread("train.25000.csv", header = TRUE)
test_dt <- fread("test.1000.csv", header = TRUE)

## compute_weightage
## based on is_booking, give weightage to the hotel cluster
## if is_booking == 1 then weightage = 1
## else weightage = 0.15
compute_weightage <- function(booking_flag) {
  sum(booking_flag) * 0.85 + length(booking_flag) * 0.15
}

# collect the srch_destination_id based on weightage of hotel_cluster
# use data.table notation of doing J expr BY group
dest_id_n_hotel_cluster_grp_count = train_dt[, compute_weightage(is_booking), by = list(srch_destination_id, hotel_cluster)]

# get the top five
# inputs : hotel_cluster and weightage
get_top_five <- function(hc, n) {
 
  # get the ordered list interms of freq. 
  # so sort them in decreasing order
  hc_ordered <- hc[order(n, decreasing = TRUE)]
  #print(hc_ordered)
  
  # we need 5, if no match, we may get 0.
  result <- min(5, length(hc_ordered))
  
  ## return the result with hc separated by spaces
  paste(hc_ordered[1:result],  collapse = " ")
}

## again use the J expr and BY group of data table  
## The package data.table creates the column with name V1
dest_id_n_top_5_hotel_cluster = dest_id_n_hotel_cluster_grp_count[ ,get_top_five(hotel_cluster, V1), by=srch_destination_id]

## Now, merge the test and top 5 clusters based on dest id.
## recommend the predicted hotel cluster
# use merge: specify both tables x & y
#          : specify the column name for merge
#          : in case of no match, add the row from x and put NA in the respective column.
recommended_hc <- merge(test_dt, dest_id_n_top_5_hotel_cluster, by = "srch_destination_id", all.x = TRUE)

## extract the id and hotel clusters
result_dt <- recommended_hc[order(id), list(id, V1)]

## set the col names
setnames(result_dt, c("id", "hotel_cluster"))

```

### Rule 2: Predict based on destination distance

Give importance for the booking when the distance between the customer and destination hotel ( `orig_destination_distance`) matches.

```{r eval = FALSE}
# create temporary data frame with the needed fields
t1_dt = train_dt[, list(orig_destination_distance, hotel_cluster, is_booking)]

# group them based on the is_booking flag with appropriate weights
t2_dt = t1_dt[, compute_weightage(is_booking), by = list(orig_destination_distance, hotel_cluster)]

# get the top five based on this rule
t3_dt  = t2_dt[ ,get_top_five(hotel_cluster, V1), by=orig_destination_distance]

# ignore if dest distance is NA
t4_dt = t3_dt[complete.cases(t3_dt),]

# merge test and training dataset.
merge_dt <- merge(test_dt, t4_dt, by = "orig_destination_distance", all.x = TRUE)

# extract the id and hotel clusters
result3_dt <- merge_dt[order(id), list(id, V1)]

## set the col names
setnames(result3_dt, c("id", "hotel_cluster"))
```


### Combine the results

Combine the results and identify the unique five by providing the precedence to the above rules. Below is the snapshot of the results.

```{r eval = FALSE}
id,hotel_cluster
0,5 37 55 11 8
1,5
2,0 31 96 91 59
3,1 45 79 24 54
4,42 28 59 91 2
5,91 42 16 48 33
6,95 21 91 2 33
7,95 91 18 68 98
8,1 45 79 24 54
...
```

The **complete R code** is available in the following github location (www.github.com/abalaji-blr/CapstoneProject/tree/master/Source/expedia_script.R).

# Results

With the Rule based approach, able to predict the hotel cluster for the given test data.
This approach yielded mean average precision at 5 (MAP@5) score of 0.47122 at the time of preparing this report. 

For more info about Mean Average precision, follow link - (www.kaggle.com/wiki/MeanAveragePrecision).
For leader board score, follow link - (www.kaggle.com/c/expedia-hotel-recommendations/leaderboard/public).

# Future Work

The advanced machine learning algorithms like Random Forest, XGboost etc. need to be evaluated to see whether they are suitable for this problem. Also note that they may require more computing resources with huge RAM - 16GB to 32GB.

# Acknowledgements

I would like to thank Nishant Sinha for his advice on handling the big dataset and reviewing the different machine learning model results.

